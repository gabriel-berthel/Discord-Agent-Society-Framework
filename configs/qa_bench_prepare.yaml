config:
  response_delay: 1
  max_random_response_delay: 0
  plan_interval: 120 # -1 = deactivated
  memories: True # -1 = deactivated
  plans: True
  model: "llama3:8b"
  base-plan: ""
  channel_id: 1
  sequential_mode: True
  random_ignore: False
  impulses: False
  save_logs: True
  persitance_prefix: 'qa_bench'
  persistance_path: 'output/qa_bench/memories'
  log_path: 'output/qa_bench/logs'

# hermes3:8b
# gemma
# mistral -> too lany emojis
# llama3:8b