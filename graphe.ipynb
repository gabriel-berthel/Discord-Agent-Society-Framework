{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc54b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.table import Table\n",
    "import uuid\n",
    "import seaborn as sns\n",
    "from math import pi\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d20acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du dossier où tu veux stocker les images\n",
    "output_folder = \"images1\"\n",
    "\n",
    "\n",
    "# Créer le dossier s'il n'existe pas\n",
    "os.makedirs(output_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a3cfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1</th>\n",
       "      <th>a2</th>\n",
       "      <th>a3</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>c1</th>\n",
       "      <th>d1</th>\n",
       "      <th>e1</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>Self-knowledge Recall,</td>\n",
       "      <td>Dialogue Recall</td>\n",
       "      <td>Reflection Recall</td>\n",
       "      <td>Context Queries Relevancy</td>\n",
       "      <td>Responder Queries Relevancy</td>\n",
       "      <td>Context Accuracy</td>\n",
       "      <td>Reflection Relevancy</td>\n",
       "      <td>Message Relevancy</td>\n",
       "      <td>Plan Relevancy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archetypes</th>\n",
       "      <td>{'nerd': {'total_score': 7, 'total_detailed_sc...</td>\n",
       "      <td>{'nerd': {'total_score': 12, 'total_detailed_s...</td>\n",
       "      <td>{'nerd': {'total_score': 13, 'total_detailed_s...</td>\n",
       "      <td>{'nerd': {'std': {'baseline': 0.01428276579827...</td>\n",
       "      <td>{'nerd': {'std': {'baseline': 0.01304950937628...</td>\n",
       "      <td>{'nerd': {'shared_keyword_ratio': 0.1274038461...</td>\n",
       "      <td>{'nerd': {'total_scores': {'personality': 25, ...</td>\n",
       "      <td>{'nerd': {'total_scores': {'personality': 29, ...</td>\n",
       "      <td>{'debunker': {'total_scores': {'personality': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            a1  \\\n",
       "description                             Self-knowledge Recall,   \n",
       "archetypes   {'nerd': {'total_score': 7, 'total_detailed_sc...   \n",
       "\n",
       "                                                            a2  \\\n",
       "description                                    Dialogue Recall   \n",
       "archetypes   {'nerd': {'total_score': 12, 'total_detailed_s...   \n",
       "\n",
       "                                                            a3  \\\n",
       "description                                  Reflection Recall   \n",
       "archetypes   {'nerd': {'total_score': 13, 'total_detailed_s...   \n",
       "\n",
       "                                                            b1  \\\n",
       "description                          Context Queries Relevancy   \n",
       "archetypes   {'nerd': {'std': {'baseline': 0.01428276579827...   \n",
       "\n",
       "                                                            b2  \\\n",
       "description                        Responder Queries Relevancy   \n",
       "archetypes   {'nerd': {'std': {'baseline': 0.01304950937628...   \n",
       "\n",
       "                                                            c1  \\\n",
       "description                                   Context Accuracy   \n",
       "archetypes   {'nerd': {'shared_keyword_ratio': 0.1274038461...   \n",
       "\n",
       "                                                            d1  \\\n",
       "description                               Reflection Relevancy   \n",
       "archetypes   {'nerd': {'total_scores': {'personality': 25, ...   \n",
       "\n",
       "                                                            e1  \\\n",
       "description                                  Message Relevancy   \n",
       "archetypes   {'nerd': {'total_scores': {'personality': 29, ...   \n",
       "\n",
       "                                                            f1  \n",
       "description                                     Plan Relevancy  \n",
       "archetypes   {'debunker': {'total_scores': {'personality': ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"results.json\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2e14c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Archetypes\n",
    "archetypes = [\"nerd\", \"debunker\", \"peacekeeper\", \"chameleon\", \"troll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "398619ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A1, A2, A3: \n",
    "for task in [\"a1\", \"a2\", \"a3\"]:\n",
    "    total_scores = [data[task][\"archetypes\"][arch][\"total_score\"] for arch in archetypes]\n",
    "    detailed_scores = [data[task][\"archetypes\"][arch][\"total_detailed_score\"] for arch in archetypes]\n",
    "    max_score = data[task][\"archetypes\"][archetypes[0]][\"max_score\"]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    x = np.arange(len(archetypes))\n",
    "    width = 0.35\n",
    "\n",
    "    ax.bar(x - width/2, total_scores, width, label=\"Total Score\", color=\"skyblue\")\n",
    "    ax.bar(x + width/2, detailed_scores, width, label=\"Total Detailed Score\", color=\"lightcoral\")\n",
    "    ax.axhline(y=max_score, color=\"gray\", linestyle=\"--\", label=f\"Max Score ({max_score})\")\n",
    "\n",
    "    ax.set_xlabel(\"Archetypes\")\n",
    "    ax.set_ylabel(\"Scores\")\n",
    "    ax.set_title(f\"{data[task]['description']} Scores by Archetype\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(archetypes, rotation=45)\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder,f\"{task}_scores.png\"))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49866d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C1: Combiner\n",
    "keyword_ratios = [data[\"c1\"][\"archetypes\"][arch][\"shared_keyword_ratio\"] for arch in archetypes]\n",
    "cosine_baseline = [data[\"c1\"][\"archetypes\"][arch][\"cosine_similarity\"][\"baseline\"] for arch in archetypes]\n",
    "cosine_agent = [data[\"c1\"][\"archetypes\"][arch][\"cosine_similarity\"][\"agent\"] for arch in archetypes]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(archetypes))\n",
    "width = 0.25\n",
    "ax.bar(x - width, keyword_ratios, width, label=\"Shared Keyword Ratio\", color=\"lightgreen\")\n",
    "ax.bar(x, cosine_baseline, width, label=\"Cosine Similarity (Baseline)\", color=\"skyblue\")\n",
    "ax.bar(x + width, cosine_agent, width, label=\"Cosine Similarity (Agent)\", color=\"lightcoral\")\n",
    "ax.set_xlabel(\"Archetypes\")\n",
    "ax.set_ylabel(\"Value\")\n",
    "ax.set_title(\"Context Accuracy: Metrics by Archetype\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(archetypes, rotation=45)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig((os.path.join(output_folder,\"c1_combined.png\")))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d1e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D1: Grouper histogram avec archetypes par colors\n",
    "metrics = [\"personality\", \"dialogue\"]\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\"]  # Colors for nerd, debunker, peacekeeper, chameleon, troll\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.15  # Width of each bar\n",
    "\n",
    "# Plot bars for each archetype\n",
    "for i, arch in enumerate(archetypes):\n",
    "    scores = [data[\"d1\"][\"archetypes\"][arch][\"average_scores\"][metric] for metric in metrics]\n",
    "    ax.bar(x + i * width, scores, width, label=arch.capitalize(), color=colors[i])\n",
    "\n",
    "ax.set_xlabel(\"Evaluation Axes\")\n",
    "ax.set_ylabel(\"Average Score\")\n",
    "ax.set_title(\"Reflection Relevancy: Scores by Archetype\")\n",
    "ax.set_xticks(x + width * (len(archetypes) - 1) / 2)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.set_ylim(0, 3.5)  # Set y-axis limit based on data range (0 to 3, with some padding)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_folder,\"d1_grouped_histogram.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "282a797d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# E1, F1: Heatmaps\n",
    "for task in [\"e1\", \"f1\"]:\n",
    "    axes = list(data[task][\"archetypes\"][archetypes[0]][\"average_scores\"].keys())\n",
    "    heatmap_data = np.array([[data[task][\"archetypes\"][arch][\"average_scores\"][axis] for axis in axes] for arch in archetypes])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", xticklabels=axes, yticklabels=archetypes)\n",
    "    ax.set_title(f\"{data[task]['description']}: Average Scores by Archetype and Axis\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_folder,f\"{task}_heatmap.png\"))\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift2125",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
